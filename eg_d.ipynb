{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from pydantic import BaseModel\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import getpass\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier:\n",
    "    def __init__(self, api_key: str  = \"AIzaSyCPfIdMffhoR2nxre5pmCFuYmvEI6G7oyY\", model_name: str = \"gemini-1.5-pro\"):\n",
    "        \n",
    "        # Configure API key\n",
    "        self.api_key = api_key\n",
    "        genai.configure(api_key=self.api_key)\n",
    "        \n",
    "        if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "            os.environ[\"GOOGLE_API_KEY\"] = self.api_key\n",
    "        \n",
    "        self.llm = ChatGoogleGenerativeAI(model=model_name,temperature=0.0, google_api_key=self.api_key, max_tokens=None)\n",
    "        \n",
    "        # Templates for classification, correction, and exercise recommendation\n",
    "        self.classifier_template = '''\n",
    "Imagine you are an expert in English, and your job is to classify the errors in the given sentence into specific categories and sub-categories based on the following:\n",
    "\n",
    "Categories:\n",
    "- Grammar: ['verb tenses', 'subject-verb agreement', 'articles', 'prepositions']\n",
    "- Vocabulary: ['word choice', 'phrasal verbs', 'collocations', 'academic vocabulary']\n",
    "- Pronunciation: ['word stress', 'intonation', 'consonant sounds', 'vowel sounds']\n",
    "- Fluency: ['speaking speed', 'hesitation', 'filler words', 'sentence linking']\n",
    "\n",
    "Input sentence: {input}\n",
    "\n",
    "Instructions:\n",
    "- Identify the **category** and **sub-category** of the mistake as an English expert.\n",
    "- Output **only** the category and sub-category in the following format: \n",
    "\n",
    "Category: [Category]  \n",
    "Sub-category: [Sub-category]\n",
    "\n",
    "### Example:\n",
    "\n",
    "Input sentence: \"She have many friends.\"\n",
    "\n",
    "Expected output:\n",
    "Category: Grammar  \n",
    "Sub-category: subject-verb agreement\n",
    "'''\n",
    "\n",
    "        self.correct_sentence_template = '''\n",
    "Imagine you are an expert in English, and your job is to correct mistakes in sentences. Given the following sentence with a mistake, provide the corrected version.\n",
    "\n",
    "Input sentence: {input}\n",
    "\n",
    "Instructions:\n",
    "- Correct any grammar, vocabulary, pronunciation (if applicable), or fluency-related mistakes in the sentence.\n",
    "- Output **only** the corrected sentence.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Input sentence: \"She have many friends.\"\n",
    "\n",
    "Expected output:\n",
    "\"She has many friends.\"\n",
    "'''\n",
    "\n",
    "\n",
    "        # Initialize prompt templates\n",
    "        self.classifier_prompt_template = PromptTemplate.from_template(self.classifier_template)\n",
    "        self.correct_sentence_prompt_template = PromptTemplate.from_template(self.correct_sentence_template)\n",
    "\n",
    "    # Method to get classifier response\n",
    "    def get_classifier_response(self, user_input: str):\n",
    "        prompt = self.classifier_prompt_template.format(input=user_input)\n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response.content\n",
    "\n",
    "    # Method to get corrected response\n",
    "    def get_corrected_response(self, user_input: str):\n",
    "        prompt = self.correct_sentence_prompt_template.format(input=user_input)\n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender:\n",
    "    def __init__(self,classifier_result, vectorstore, api_key: str = \"AIzaSyCPfIdMffhoR2nxre5pmCFuYmvEI6G7oyY\", model_name: str = \"gemini-1.5-pro\"):\n",
    "        \n",
    "        # Configure API key\n",
    "        self.api_key = api_key\n",
    "        self.vectorstore = vectorstore\n",
    "        genai.configure(api_key=self.api_key)\n",
    "        \n",
    "        if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "            os.environ[\"GOOGLE_API_KEY\"] = self.api_key\n",
    "        \n",
    "        # Initialize LLM\n",
    "        self.llm = ChatGoogleGenerativeAI(model=model_name,temperature=0.0, google_api_key=self.api_key, max_tokens=None)\n",
    "\n",
    "        self.d = self.vectorstore.similarity_search(classifier_result,k=1)                       # Example to retrive the contents using the Similarity search\n",
    "        self.exer = self.d[0].page_content\n",
    "\n",
    "        self.exercise_recommender_template = '''\n",
    "Imagine you are an expert in language learning, and your job is to recommend exercises based on a user's demographics, mistake history, and preferred exercise type.\n",
    "\n",
    "User demographics:\n",
    "{user_demographic}\n",
    "\n",
    "Mistake history:\n",
    "{Mistake_history}\n",
    "\n",
    "preferred exercise type:\n",
    "{reco_exercise}\n",
    "\n",
    "\n",
    "Instructions to follow:\n",
    "- Based on the user's demographics, mistake history, and preferred exercise type, only 1 exercise.\n",
    "- Output the exercise recommendation in a clear, concise format.\n",
    "- Output only the exercise \n",
    "\n",
    "Here is an example case:\n",
    "Given the user demographics,history and exercise\n",
    "Expected output:\n",
    "Naruto is ___ ninja who dreams of becoming Hokage.\n",
    "Luffy from \"One Piece\" set out to become ___ king of ___ pirates.\n",
    "After watching ___ episode of \"Attack on Titan,\" I felt ___ sense of excitement.\n",
    "'''\n",
    "      \n",
    "        self.exercise_recommender_prompt_template = PromptTemplate.from_template(self.exercise_recommender_template)\n",
    "\n",
    "    \n",
    "    def get_exercise(self, user_ud: str, user_hist: str):\n",
    "        prompt = self.exercise_recommender_prompt_template.format(\n",
    "            user_demographic=user_ud, \n",
    "            Mistake_history=user_hist, \n",
    "            reco_exercise=self.exer\n",
    "        )\n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"AIzaSyCPfIdMffhoR2nxre5pmCFuYmvEI6G7oyY\"\n",
    "genai.configure(api_key=api_key)\n",
    "        \n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "loader = DirectoryLoader(path=\"Exercises/\", glob=\"**/*.txt\")\n",
    "pages = loader.load()\n",
    "\n",
    "# Embedding model and vector store\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "            documents=pages, \n",
    "            embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiko_ud = '''\n",
    "    \"name\": \"Aiko\",\n",
    "    \"age\": 22,\n",
    "    \"proficiency_level\": \"intermediate\",\n",
    "    \"country\": \"Japan\",\n",
    "    \"interests\": [\"anime\", \"movies\", \"technology\", \"fashion\"],\n",
    "'''\n",
    "aiko_history = '''\n",
    "Incorrect verb tense in conditional sentence (Grammar - Verb tenses)\n",
    "Subject-verb agreement error (Grammar - Subject-verb agreement)\n",
    "Used incorrect articles (Grammar - Articles)\n",
    "Failed to link ideas (Fluency - Sentence linking)\n",
    "Preposition misuse (Grammar - Prepositions)\n",
    "Inconsistent stress patterns (Pronunciation - Word stress)\n",
    "Mispronounced verb forms (Pronunciation - Consonant sounds)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Fluency\n",
      "Sub-category: Filler words \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Question = \"Whaccha doin? Its veryyy impaaartant matter\"\n",
    "Question = \"I need to buy milk and bread and uh, eggs\"\n",
    "res = tool.get_classifier_response(Question)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I need to buy milk, bread, and eggs. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tool.get_corrected_response(Question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2 = Recommender(res,vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aiko, imagine you are a famous technology reviewer in Japan.  Describe your favorite piece of technology and why you recommend it, paying close attention to your verb tenses.  Try to speak for one minute without using any filler words. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res2 = tool2.get_exercise(aiko_ud,aiko_history)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
